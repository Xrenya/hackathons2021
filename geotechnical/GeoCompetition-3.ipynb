{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GeoCompetition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4u_CJtJD0Uk"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pickle\n",
        "from lightgbm import LGBMClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from typing import List\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.utils.class_weight import compute_sample_weight, compute_class_weight\n",
        "from imblearn.under_sampling import RandomUnderSampler \n",
        "import collections\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFsWG58jG2hZ",
        "outputId": "a6ddd2cc-a392-4d80-d4c6-0275a97e0f09"
      },
      "source": [
        "df_val = pd.read_csv('Validation-dataset.csv')\n",
        "df_val.info()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28997 entries, 0 to 28996\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   WELL                      28997 non-null  object \n",
            " 1   X                         28997 non-null  float64\n",
            " 2   Y                         28997 non-null  float64\n",
            " 3   MD                        28997 non-null  float64\n",
            " 4   GR                        28997 non-null  float64\n",
            " 5   RT                        28997 non-null  float64\n",
            " 6   CN                        28997 non-null  float64\n",
            " 7   DEN                       28997 non-null  float64\n",
            " 8   DEPOSITIONAL_ENVIRONMENT  28997 non-null  object \n",
            "dtypes: float64(7), object(2)\n",
            "memory usage: 2.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "7XsTEazGJfQz",
        "outputId": "2ae6ecb8-7d10-4e04-e60b-875d67c5fa41"
      },
      "source": [
        "print(df_val.isnull().values.any())\n",
        "df_val.sample()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WELL</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>MD</th>\n",
              "      <th>GR</th>\n",
              "      <th>RT</th>\n",
              "      <th>CN</th>\n",
              "      <th>DEN</th>\n",
              "      <th>DEPOSITIONAL_ENVIRONMENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7308</th>\n",
              "      <td>Well-X</td>\n",
              "      <td>2.9956</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>1627.865</td>\n",
              "      <td>106.0913</td>\n",
              "      <td>1.4066</td>\n",
              "      <td>0.3182</td>\n",
              "      <td>2.3552</td>\n",
              "      <td>Transitional</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        WELL       X       Y  ...      CN     DEN  DEPOSITIONAL_ENVIRONMENT\n",
              "7308  Well-X  2.9956  0.0061  ...  0.3182  2.3552              Transitional\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "xmrMU-Hel1lC",
        "outputId": "d5b46ca9-515d-48ff-8c4e-133df849a992"
      },
      "source": [
        "df_val.describe()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>MD</th>\n",
              "      <th>GR</th>\n",
              "      <th>RT</th>\n",
              "      <th>CN</th>\n",
              "      <th>DEN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>28997.000000</td>\n",
              "      <td>28997.000000</td>\n",
              "      <td>28997.000000</td>\n",
              "      <td>28997.000000</td>\n",
              "      <td>28997.000000</td>\n",
              "      <td>28997.000000</td>\n",
              "      <td>28997.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.226964</td>\n",
              "      <td>1.750205</td>\n",
              "      <td>1227.801576</td>\n",
              "      <td>84.103308</td>\n",
              "      <td>4.314957</td>\n",
              "      <td>0.337462</td>\n",
              "      <td>2.208479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.178670</td>\n",
              "      <td>1.090184</td>\n",
              "      <td>289.111458</td>\n",
              "      <td>14.677383</td>\n",
              "      <td>2.831058</td>\n",
              "      <td>0.062961</td>\n",
              "      <td>0.135494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.034400</td>\n",
              "      <td>0.006100</td>\n",
              "      <td>645.373000</td>\n",
              "      <td>35.166500</td>\n",
              "      <td>0.008680</td>\n",
              "      <td>0.126370</td>\n",
              "      <td>1.431400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.034400</td>\n",
              "      <td>0.006100</td>\n",
              "      <td>991.665000</td>\n",
              "      <td>76.238900</td>\n",
              "      <td>3.264980</td>\n",
              "      <td>0.290410</td>\n",
              "      <td>2.113500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.147500</td>\n",
              "      <td>2.131000</td>\n",
              "      <td>1233.273000</td>\n",
              "      <td>85.604200</td>\n",
              "      <td>3.815280</td>\n",
              "      <td>0.329890</td>\n",
              "      <td>2.201400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.995600</td>\n",
              "      <td>2.689300</td>\n",
              "      <td>1474.900000</td>\n",
              "      <td>93.001300</td>\n",
              "      <td>4.658960</td>\n",
              "      <td>0.375030</td>\n",
              "      <td>2.322700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.995600</td>\n",
              "      <td>2.689300</td>\n",
              "      <td>1748.073000</td>\n",
              "      <td>142.771900</td>\n",
              "      <td>122.294700</td>\n",
              "      <td>0.699350</td>\n",
              "      <td>2.701900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  X             Y  ...            CN           DEN\n",
              "count  28997.000000  28997.000000  ...  28997.000000  28997.000000\n",
              "mean       1.226964      1.750205  ...      0.337462      2.208479\n",
              "std        1.178670      1.090184  ...      0.062961      0.135494\n",
              "min        0.034400      0.006100  ...      0.126370      1.431400\n",
              "25%        0.034400      0.006100  ...      0.290410      2.113500\n",
              "50%        1.147500      2.131000  ...      0.329890      2.201400\n",
              "75%        2.995600      2.689300  ...      0.375030      2.322700\n",
              "max        2.995600      2.689300  ...      0.699350      2.701900\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWVJtu8GFSL4",
        "outputId": "089e7dad-051f-4623-db38-0b5b7acc8fc6"
      },
      "source": [
        "df = pd.read_csv('Train-dataset.csv')\n",
        "print(df.isnull().values.any())\n",
        "df.info()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 45749 entries, 0 to 45748\n",
            "Data columns (total 11 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   WELL                      45749 non-null  object \n",
            " 1   X                         45749 non-null  float64\n",
            " 2   Y                         45749 non-null  float64\n",
            " 3   MD                        45749 non-null  float64\n",
            " 4   GR                        45749 non-null  float64\n",
            " 5   RT                        45749 non-null  float64\n",
            " 6   CN                        45749 non-null  float64\n",
            " 7   DEN                       45749 non-null  float64\n",
            " 8   DEPOSITIONAL_ENVIRONMENT  45749 non-null  object \n",
            " 9   LITH_NAME                 45749 non-null  object \n",
            " 10  LITH_CODE                 45749 non-null  int64  \n",
            "dtypes: float64(7), int64(1), object(3)\n",
            "memory usage: 3.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "P0YWHtxfld20",
        "outputId": "b713ad4f-cf4b-45a9-9064-d8475a72431d"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>MD</th>\n",
              "      <th>GR</th>\n",
              "      <th>RT</th>\n",
              "      <th>CN</th>\n",
              "      <th>DEN</th>\n",
              "      <th>LITH_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.670183</td>\n",
              "      <td>1.428714</td>\n",
              "      <td>1289.498006</td>\n",
              "      <td>84.873762</td>\n",
              "      <td>5.385460</td>\n",
              "      <td>0.345358</td>\n",
              "      <td>2.201688</td>\n",
              "      <td>594.933223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.015506</td>\n",
              "      <td>1.099132</td>\n",
              "      <td>387.339595</td>\n",
              "      <td>15.915062</td>\n",
              "      <td>74.537883</td>\n",
              "      <td>0.076597</td>\n",
              "      <td>0.152785</td>\n",
              "      <td>374.113902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.364000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>640.983000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.444750</td>\n",
              "      <td>0.062000</td>\n",
              "      <td>1.381500</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.756400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>980.300000</td>\n",
              "      <td>75.904300</td>\n",
              "      <td>3.130500</td>\n",
              "      <td>0.292170</td>\n",
              "      <td>2.098700</td>\n",
              "      <td>400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.310900</td>\n",
              "      <td>1.983300</td>\n",
              "      <td>1231.900000</td>\n",
              "      <td>86.297800</td>\n",
              "      <td>3.750600</td>\n",
              "      <td>0.333630</td>\n",
              "      <td>2.197695</td>\n",
              "      <td>500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.091200</td>\n",
              "      <td>1562.183000</td>\n",
              "      <td>95.251900</td>\n",
              "      <td>4.652600</td>\n",
              "      <td>0.387720</td>\n",
              "      <td>2.330100</td>\n",
              "      <td>600.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2275.600000</td>\n",
              "      <td>146.509000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>0.794296</td>\n",
              "      <td>2.725900</td>\n",
              "      <td>1500.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  X             Y  ...           DEN     LITH_CODE\n",
              "count  45749.000000  45749.000000  ...  45749.000000  45749.000000\n",
              "mean       1.670183      1.428714  ...      2.201688    594.933223\n",
              "std        1.015506      1.099132  ...      0.152785    374.113902\n",
              "min        0.364000      0.000000  ...      1.381500    100.000000\n",
              "25%        0.756400      0.000000  ...      2.098700    400.000000\n",
              "50%        1.310900      1.983300  ...      2.197695    500.000000\n",
              "75%        3.000000      2.091200  ...      2.330100    600.000000\n",
              "max        3.000000      3.000000  ...      2.725900   1500.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "nakbeOzVHSe_",
        "outputId": "2c9ba6c8-bc9d-4579-dfa8-6fad1279f0b9"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WELL</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>MD</th>\n",
              "      <th>GR</th>\n",
              "      <th>RT</th>\n",
              "      <th>CN</th>\n",
              "      <th>DEN</th>\n",
              "      <th>DEPOSITIONAL_ENVIRONMENT</th>\n",
              "      <th>LITH_NAME</th>\n",
              "      <th>LITH_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14326</th>\n",
              "      <td>Well-11</td>\n",
              "      <td>0.7564</td>\n",
              "      <td>1.9833</td>\n",
              "      <td>1323.500</td>\n",
              "      <td>71.51500</td>\n",
              "      <td>5.61900</td>\n",
              "      <td>0.34477</td>\n",
              "      <td>2.15600</td>\n",
              "      <td>Transitional</td>\n",
              "      <td>Sandstone</td>\n",
              "      <td>600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29348</th>\n",
              "      <td>Well-7</td>\n",
              "      <td>1.3109</td>\n",
              "      <td>2.0912</td>\n",
              "      <td>1656.583</td>\n",
              "      <td>109.23180</td>\n",
              "      <td>2.93558</td>\n",
              "      <td>0.29591</td>\n",
              "      <td>2.44820</td>\n",
              "      <td>Marine</td>\n",
              "      <td>Clay marl</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40890</th>\n",
              "      <td>Well-10</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1789.800</td>\n",
              "      <td>93.98840</td>\n",
              "      <td>2.97968</td>\n",
              "      <td>0.30852</td>\n",
              "      <td>2.40530</td>\n",
              "      <td>Marine</td>\n",
              "      <td>Clay marl</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>Well-7</td>\n",
              "      <td>1.3109</td>\n",
              "      <td>2.0912</td>\n",
              "      <td>1221.383</td>\n",
              "      <td>96.41016</td>\n",
              "      <td>2.93636</td>\n",
              "      <td>0.42694</td>\n",
              "      <td>2.19917</td>\n",
              "      <td>Transitional</td>\n",
              "      <td>Clay</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44151</th>\n",
              "      <td>Well-10</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2115.900</td>\n",
              "      <td>94.35700</td>\n",
              "      <td>1.95870</td>\n",
              "      <td>0.29069</td>\n",
              "      <td>2.42990</td>\n",
              "      <td>Marine</td>\n",
              "      <td>Clay marl</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          WELL       X       Y  ...  DEPOSITIONAL_ENVIRONMENT  LITH_NAME  LITH_CODE\n",
              "14326  Well-11  0.7564  1.9833  ...              Transitional  Sandstone        600\n",
              "29348   Well-7  1.3109  2.0912  ...                    Marine  Clay marl        400\n",
              "40890  Well-10  3.0000  0.0000  ...                    Marine  Clay marl        400\n",
              "24996   Well-7  1.3109  2.0912  ...              Transitional       Clay        100\n",
              "44151  Well-10  3.0000  0.0000  ...                    Marine  Clay marl        400\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9T0z3TBJOiq",
        "outputId": "617c34ef-133d-4610-aac0-dacea63ba865"
      },
      "source": [
        "df.isnull().values.any()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7MMC4d8M3jt"
      },
      "source": [
        "encoder = {}\n",
        "decoder = {}\n",
        "for i, code in enumerate(df['LITH_CODE'].unique()):\n",
        "    decoder[i] = code\n",
        "    encoder[code] = i"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fNkFLgmHWO_"
      },
      "source": [
        "feature = ['MD','GR', 'RT', 'DEN', 'CN', 'DEPOSITIONAL_ENVIRONMENT']\n",
        "numeric_features = ['MD','GR', 'RT', 'DEN', 'CN']\n",
        "categorical_features = ['DEPOSITIONAL_ENVIRONMENT']"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm2Ha1K2MsPV"
      },
      "source": [
        "X = df[feature]\n",
        "y = df['LITH_CODE'].apply(lambda x: encoder[x])\n",
        "X_val = df_val[feature]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yliay8yFBg2"
      },
      "source": [
        "def data_preprocessing(df: pd.DataFrame,\n",
        "                       categorical_features: List[str],\n",
        "                       numeric_features: List[str],\n",
        "                       scale_strategies) -> pd.DataFrame:\n",
        "    numeric_transformer = Pipeline(\n",
        "        steps=[\n",
        "            ('scaler', scale_strategies)\n",
        "        ]\n",
        "    )\n",
        "    #One-hot encoder\n",
        "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "    \n",
        "    # Preprocessing\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('numerical', numeric_transformer, numeric_features),\n",
        "            ('categorical', categorical_transformer, categorical_features)\n",
        "        ]\n",
        "    )\n",
        "    return preprocessor"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntqo3JsLMXRq",
        "outputId": "218db32e-3ba4-4f3c-9f37-be85226c1bee"
      },
      "source": [
        "classifiers = [\n",
        "    #KNeighborsClassifier(3), 0.834\n",
        "    #SVC(kernel=\"rbf\", C=0.025, probability=True),0.734\n",
        "    xgb.XGBClassifier(),\n",
        "    LGBMClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier()\n",
        "]\n",
        "for classifier in classifiers:\n",
        "    preprocessor = data_preprocessing(X_train,\n",
        "                                      categorical_features,\n",
        "                                      numeric_features,\n",
        "                                      StandardScaler())\n",
        "\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                          ('model', classifier)])\n",
        "    pipe.fit(X_train, y_train)   \n",
        "    print(classifier)\n",
        "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "model score: 0.831\n",
            "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
            "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
            "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
            "model score: 0.743\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "model score: 0.911\n",
            "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
            "                   n_estimators=50, random_state=None)\n",
            "model score: 0.564\n",
            "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='deprecated',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "model score: 0.857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTp6gutDP6nJ",
        "outputId": "3db03ec3-2cb3-4a3c-c98a-90dac08ec401"
      },
      "source": [
        "classifier = RandomForestClassifier()\n",
        "\n",
        "preprocessor = data_preprocessing(X_train,\n",
        "                                    categorical_features,\n",
        "                                    numeric_features,\n",
        "                                    StandardScaler())\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "pipe.fit(X_train, y_train)   \n",
        "print(classifier)\n",
        "print(\"model score: %.3f\" % pipe.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "model score: 0.916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLosZU_KZ68c",
        "outputId": "604af086-69ff-43a0-e31e-2626d6531845"
      },
      "source": [
        "classifier = RandomForestClassifier()\n",
        "\n",
        "preprocessor = data_preprocessing(X_train,\n",
        "                                    categorical_features,\n",
        "                                    numeric_features,\n",
        "                                    StandardScaler())\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "\n",
        "param_grid = {\n",
        "    'model__max_depth': [2, 3, 5, 7, 10],\n",
        "    'model__n_estimators': [25, 50, 100, 150, 200],\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(estimator=pipe, cv=5,\n",
        "                  param_grid=param_grid)\n",
        "cv.fit(X_train, y_train)\n",
        "print(classifier)\n",
        "print(cv.best_params_)\n",
        "print(\"model score: %.3f\" % cv.best_estimator_.score(X_test, y_test))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "{'model__max_depth': 10, 'model__n_estimators': 150}\n",
            "model score: 0.848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2_2R082fLa4",
        "outputId": "29e2cd0d-0c7b-4d6e-f2ea-d8eaa42721c1"
      },
      "source": [
        "classifier = RandomForestClassifier(class_weight='balanced')\n",
        "\n",
        "preprocessor = data_preprocessing(X_train,\n",
        "                                    categorical_features,\n",
        "                                    numeric_features,\n",
        "                                    StandardScaler())\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "pipe.fit(X_train, y_train)   \n",
        "print(classifier)\n",
        "print(\"model score: %.3f\" % pipe.score(X_test, y_test))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "model score: 0.915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcqdQhYbS47k",
        "outputId": "5a55a1da-1f41-4da1-a753-d64da320d8f5"
      },
      "source": [
        "preds = pipe.predict(X_val)\n",
        "preds"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5,  5,  5, ..., 10, 10, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEAjFkm1UoZm"
      },
      "source": [
        "predictions = []\n",
        "for pred in preds:\n",
        "    predictions.append(decoder[pred])"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUZs_JO0VFHc"
      },
      "source": [
        "np.savetxt('prediction.csv', predictions, delimiter=',', encoding='utf-8') "
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZMarhH4V8tt"
      },
      "source": [
        "X = df[feature]\n",
        "y = df['LITH_CODE'].apply(lambda x: encoder[x])\n",
        "X_val = df_val[feature]\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J-yHcdEpaPB",
        "outputId": "58c24b50-afee-45c1-b842-653354119419"
      },
      "source": [
        "import collections\n",
        "count = collections.Counter(y)\n",
        "count"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 889,\n",
              "         1: 5677,\n",
              "         2: 11572,\n",
              "         3: 443,\n",
              "         4: 83,\n",
              "         5: 7716,\n",
              "         6: 340,\n",
              "         7: 693,\n",
              "         8: 6496,\n",
              "         9: 1236,\n",
              "         10: 8054,\n",
              "         11: 3,\n",
              "         12: 2547})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qB4tanOrzyH"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5jaPoAWsd1M",
        "outputId": "bbc808a1-f19f-4dfa-a1c5-6b8fe33f0ac5"
      },
      "source": [
        "X = df[feature]\n",
        "y = df['LITH_CODE'].apply(lambda x: encoder[x])\n",
        "X_val = df_val[feature]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "# fit and apply the transform\n",
        "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
        "# summarize class distribution\n",
        "print(collections.Counter(y_train))\n",
        "print(collections.Counter(y_over))\n",
        "df_over = pd.DataFrame(data = X_over,\n",
        "                  columns = X.columns.to_list())"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({2: 9275, 10: 6403, 5: 6151, 8: 5227, 1: 4572, 12: 2045, 9: 985, 0: 714, 7: 545, 3: 349, 6: 267, 4: 64, 11: 2})\n",
            "Counter({2: 9275, 11: 9275, 10: 6403, 5: 6151, 8: 5227, 1: 4572, 12: 2045, 9: 985, 0: 714, 7: 545, 3: 349, 6: 267, 4: 64})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnmQdevfuMp9",
        "outputId": "77eadf1f-c7a3-43dd-b9c6-305cba2c4445"
      },
      "source": [
        "classifier = RandomForestClassifier()\n",
        "\n",
        "preprocessor = data_preprocessing(df_over,\n",
        "                                  categorical_features,\n",
        "                                  numeric_features,\n",
        "                                  StandardScaler())\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "pipe.fit(df_over, y_over)   \n",
        "print(classifier)\n",
        "print(\"model score: %.3f\" % pipe.score(X_test, y_test))"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "model score: 0.911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55orNNQuxpjv",
        "outputId": "217ff0de-3a81-4530-94e5-7f7d8c36f517"
      },
      "source": [
        "names = y_train.unique()\n",
        "collections.Counter(y_train)"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 714,\n",
              "         1: 4572,\n",
              "         2: 9275,\n",
              "         3: 349,\n",
              "         4: 64,\n",
              "         5: 6151,\n",
              "         6: 267,\n",
              "         7: 545,\n",
              "         8: 5227,\n",
              "         9: 985,\n",
              "         10: 6403,\n",
              "         11: 2,\n",
              "         12: 2045})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkO2JHwAvXVA"
      },
      "source": [
        "max_samples = 985"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "LurKV6_XxyEy",
        "outputId": "b3ab1e3e-dd0c-4fea-f95d-26fdfa3d32ac"
      },
      "source": [
        "df_train = X_train.join(y_train)\n",
        "df_train"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MD</th>\n",
              "      <th>GR</th>\n",
              "      <th>RT</th>\n",
              "      <th>DEN</th>\n",
              "      <th>CN</th>\n",
              "      <th>DEPOSITIONAL_ENVIRONMENT</th>\n",
              "      <th>LITH_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31402</th>\n",
              "      <td>841.000</td>\n",
              "      <td>110.3697</td>\n",
              "      <td>4.20527</td>\n",
              "      <td>2.102200</td>\n",
              "      <td>0.384470</td>\n",
              "      <td>Continental</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45407</th>\n",
              "      <td>2241.500</td>\n",
              "      <td>81.5272</td>\n",
              "      <td>2.02112</td>\n",
              "      <td>2.419500</td>\n",
              "      <td>0.280210</td>\n",
              "      <td>Marine</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45074</th>\n",
              "      <td>2208.200</td>\n",
              "      <td>102.2406</td>\n",
              "      <td>3.11045</td>\n",
              "      <td>2.482800</td>\n",
              "      <td>0.273900</td>\n",
              "      <td>Marine</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43427</th>\n",
              "      <td>2043.500</td>\n",
              "      <td>92.9224</td>\n",
              "      <td>4.05848</td>\n",
              "      <td>2.457500</td>\n",
              "      <td>0.242690</td>\n",
              "      <td>Marine</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6031</th>\n",
              "      <td>1049.800</td>\n",
              "      <td>83.8033</td>\n",
              "      <td>3.71400</td>\n",
              "      <td>2.200675</td>\n",
              "      <td>0.360977</td>\n",
              "      <td>Continental</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4019</th>\n",
              "      <td>848.200</td>\n",
              "      <td>59.6182</td>\n",
              "      <td>6.72760</td>\n",
              "      <td>2.014838</td>\n",
              "      <td>0.394977</td>\n",
              "      <td>Continental</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31007</th>\n",
              "      <td>801.500</td>\n",
              "      <td>83.9968</td>\n",
              "      <td>4.73844</td>\n",
              "      <td>2.186100</td>\n",
              "      <td>0.345800</td>\n",
              "      <td>Continental</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21064</th>\n",
              "      <td>828.183</td>\n",
              "      <td>96.7721</td>\n",
              "      <td>3.90289</td>\n",
              "      <td>2.071760</td>\n",
              "      <td>0.443140</td>\n",
              "      <td>Continental</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30257</th>\n",
              "      <td>726.500</td>\n",
              "      <td>96.2957</td>\n",
              "      <td>5.33277</td>\n",
              "      <td>2.092200</td>\n",
              "      <td>0.364990</td>\n",
              "      <td>Continental</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44876</th>\n",
              "      <td>2188.400</td>\n",
              "      <td>105.8638</td>\n",
              "      <td>2.15958</td>\n",
              "      <td>2.430000</td>\n",
              "      <td>0.283360</td>\n",
              "      <td>Marine</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36599 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             MD        GR  ...  DEPOSITIONAL_ENVIRONMENT  LITH_CODE\n",
              "31402   841.000  110.3697  ...               Continental          3\n",
              "45407  2241.500   81.5272  ...                    Marine          2\n",
              "45074  2208.200  102.2406  ...                    Marine         10\n",
              "43427  2043.500   92.9224  ...                    Marine         10\n",
              "6031   1049.800   83.8033  ...               Continental          8\n",
              "...         ...       ...  ...                       ...        ...\n",
              "4019    848.200   59.6182  ...               Continental          2\n",
              "31007   801.500   83.9968  ...               Continental          8\n",
              "21064   828.183   96.7721  ...               Continental          5\n",
              "30257   726.500   96.2957  ...               Continental          5\n",
              "44876  2188.400  105.8638  ...                    Marine          2\n",
              "\n",
              "[36599 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "9cF7g0_rzgvo",
        "outputId": "de4aa041-4d9f-4d0f-f0da-b0658ada4cfa"
      },
      "source": [
        "new_df = pd.DataFrame(columns = df_train.columns.to_list())\n",
        "new_df"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MD</th>\n",
              "      <th>GR</th>\n",
              "      <th>RT</th>\n",
              "      <th>DEN</th>\n",
              "      <th>CN</th>\n",
              "      <th>DEPOSITIONAL_ENVIRONMENT</th>\n",
              "      <th>LITH_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [MD, GR, RT, DEN, CN, DEPOSITIONAL_ENVIRONMENT, LITH_CODE]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXuPvgw_3qPx",
        "outputId": "80dd8ed7-360b-4023-c9dc-a66d6a7840c5"
      },
      "source": [
        "df_train['LITH_CODE'].unique()"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2,  8,  5,  1, 10,  9, 12,  3,  7,  0,  6,  4, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViSxNRznyKZQ"
      },
      "source": [
        "for key in df_train['LITH_CODE'].unique():\n",
        "    if len(df_train[df_train['LITH_CODE'] == key]) < max_samples:\n",
        "        new_df = new_df.append(df_train[df_train['LITH_CODE'] == key])\n",
        "    else:\n",
        "        temp = df_train[df_train['LITH_CODE'] == key].sample(max_samples)\n",
        "        new_df = new_df.append(temp)"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPRI9hhU0nTR"
      },
      "source": [
        "new_df.reset_index(inplace=True)"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "uXaCBih31dJb",
        "outputId": "6f35191d-0329-41f6-ced2-77f57c39a1a3"
      },
      "source": [
        "new_df.drop(columns='index')"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MD</th>\n",
              "      <th>GR</th>\n",
              "      <th>RT</th>\n",
              "      <th>DEN</th>\n",
              "      <th>CN</th>\n",
              "      <th>DEPOSITIONAL_ENVIRONMENT</th>\n",
              "      <th>LITH_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1951.400</td>\n",
              "      <td>102.38220</td>\n",
              "      <td>3.35595</td>\n",
              "      <td>2.35010</td>\n",
              "      <td>0.24663</td>\n",
              "      <td>Marine</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893.600</td>\n",
              "      <td>49.51060</td>\n",
              "      <td>6.88370</td>\n",
              "      <td>1.98520</td>\n",
              "      <td>0.35190</td>\n",
              "      <td>Continental</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1029.983</td>\n",
              "      <td>48.32566</td>\n",
              "      <td>7.12176</td>\n",
              "      <td>1.95737</td>\n",
              "      <td>0.27762</td>\n",
              "      <td>Continental</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1494.900</td>\n",
              "      <td>65.06830</td>\n",
              "      <td>3.12140</td>\n",
              "      <td>2.08720</td>\n",
              "      <td>0.27477</td>\n",
              "      <td>Transitional</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1403.900</td>\n",
              "      <td>67.25640</td>\n",
              "      <td>4.31681</td>\n",
              "      <td>2.17660</td>\n",
              "      <td>0.32665</td>\n",
              "      <td>Transitional</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8831</th>\n",
              "      <td>1398.000</td>\n",
              "      <td>77.31000</td>\n",
              "      <td>4.95400</td>\n",
              "      <td>2.39000</td>\n",
              "      <td>0.28000</td>\n",
              "      <td>Transitional</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8832</th>\n",
              "      <td>1149.900</td>\n",
              "      <td>72.87000</td>\n",
              "      <td>3.61800</td>\n",
              "      <td>2.15000</td>\n",
              "      <td>0.42000</td>\n",
              "      <td>Transitional</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8833</th>\n",
              "      <td>1395.600</td>\n",
              "      <td>78.56000</td>\n",
              "      <td>4.61700</td>\n",
              "      <td>2.37000</td>\n",
              "      <td>0.30000</td>\n",
              "      <td>Transitional</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8834</th>\n",
              "      <td>1802.500</td>\n",
              "      <td>33.40000</td>\n",
              "      <td>6.22500</td>\n",
              "      <td>2.48000</td>\n",
              "      <td>0.14000</td>\n",
              "      <td>Marine</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8835</th>\n",
              "      <td>1802.700</td>\n",
              "      <td>32.54000</td>\n",
              "      <td>5.31000</td>\n",
              "      <td>2.38000</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>Marine</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8836 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            MD         GR       RT  ...       CN  DEPOSITIONAL_ENVIRONMENT LITH_CODE\n",
              "0     1951.400  102.38220  3.35595  ...  0.24663                    Marine         2\n",
              "1      893.600   49.51060  6.88370  ...  0.35190               Continental         2\n",
              "2     1029.983   48.32566  7.12176  ...  0.27762               Continental         2\n",
              "3     1494.900   65.06830  3.12140  ...  0.27477              Transitional         2\n",
              "4     1403.900   67.25640  4.31681  ...  0.32665              Transitional         2\n",
              "...        ...        ...      ...  ...      ...                       ...       ...\n",
              "8831  1398.000   77.31000  4.95400  ...  0.28000              Transitional         4\n",
              "8832  1149.900   72.87000  3.61800  ...  0.42000              Transitional         4\n",
              "8833  1395.600   78.56000  4.61700  ...  0.30000              Transitional         4\n",
              "8834  1802.500   33.40000  6.22500  ...  0.14000                    Marine        11\n",
              "8835  1802.700   32.54000  5.31000  ...  0.17000                    Marine        11\n",
              "\n",
              "[8836 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbXSf5T42zGU"
      },
      "source": [
        "y_new_df = new_df['LITH_CODE']\n",
        "X_new_df = new_df.drop(columns=['LITH_CODE', 'index'])"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRqshdhH1qYK",
        "outputId": "ca5bed2f-27e5-46ff-a2ba-3754b26505bd"
      },
      "source": [
        "classifier = RandomForestClassifier()\n",
        "\n",
        "preprocessor = data_preprocessing(X_new_df,\n",
        "                                  categorical_features,\n",
        "                                  numeric_features,\n",
        "                                  StandardScaler())\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "pipe.fit(X_new_df, y_new_df.astype('int'))   \n",
        "print(classifier)\n",
        "print(\"model score: %.3f\" % pipe.score(X_test, y_test))"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "model score: 0.856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3U2JzA16mHl",
        "outputId": "8f4e2313-ed95-43a9-ea0e-c0176304f01f"
      },
      "source": [
        "classifier = RandomForestClassifier(class_weight='balanced')\n",
        "\n",
        "preprocessor = data_preprocessing(X_new_df,\n",
        "                                  categorical_features,\n",
        "                                  numeric_features,\n",
        "                                  StandardScaler())\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "pipe.fit(X_new_df, y_new_df.astype('int'))   \n",
        "print(classifier)\n",
        "print(\"model score: %.3f\" % pipe.score(X_test, y_test))"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "model score: 0.854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb0tLV7l9Clm"
      },
      "source": [
        "combined_predictions = []"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W-xePcd70_p",
        "outputId": "5a72eefe-757f-40f5-a78e-7994e7d52664"
      },
      "source": [
        "for j in range(10):\n",
        "    new_df = pd.DataFrame(columns = df_train.columns.to_list())\n",
        "    for key in df_train['LITH_CODE'].unique():\n",
        "        if len(df_train[df_train['LITH_CODE'] == key]) < max_samples:\n",
        "            new_df = new_df.append(df_train[df_train['LITH_CODE'] == key])\n",
        "        else:\n",
        "            temp = df_train[df_train['LITH_CODE'] == key].sample(max_samples, random_state=np.random.randint(1, 200))\n",
        "            new_df = new_df.append(temp)\n",
        "    y_new_df = new_df['LITH_CODE']\n",
        "    X_new_df = new_df.drop(columns=['LITH_CODE'])\n",
        "    if j % 2 == 0:\n",
        "        classifier = RandomForestClassifier(class_weight='balanced')\n",
        "    else:\n",
        "        classifier = RandomForestClassifier()\n",
        "\n",
        "    preprocessor = data_preprocessing(X_new_df,\n",
        "                                      categorical_features,\n",
        "                                      numeric_features,\n",
        "                                      StandardScaler())\n",
        "\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                            ('model', classifier)])\n",
        "    pipe.fit(X_new_df, y_new_df.astype('int'))   \n",
        "    #print(classifier)\n",
        "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
        "    combined_predictions.append(pipe.predict(X_val))"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [MD, GR, RT, DEN, CN, DEPOSITIONAL_ENVIRONMENT, LITH_CODE]\n",
            "Index: []\n",
            "model score: 0.852\n",
            "Empty DataFrame\n",
            "Columns: [MD, GR, RT, DEN, CN, DEPOSITIONAL_ENVIRONMENT, LITH_CODE]\n",
            "Index: []\n",
            "model score: 0.849\n",
            "Empty DataFrame\n",
            "Columns: [MD, GR, RT, DEN, CN, DEPOSITIONAL_ENVIRONMENT, LITH_CODE]\n",
            "Index: []\n",
            "model score: 0.857\n",
            "Empty DataFrame\n",
            "Columns: [MD, GR, RT, DEN, CN, DEPOSITIONAL_ENVIRONMENT, LITH_CODE]\n",
            "Index: []\n",
            "model score: 0.853\n",
            "Empty DataFrame\n",
            "Columns: [MD, GR, RT, DEN, CN, DEPOSITIONAL_ENVIRONMENT, LITH_CODE]\n",
            "Index: []\n",
            "model score: 0.858\n",
            "Empty DataFrame\n",
            "Columns: [MD, GR, RT, DEN, CN, DEPOSITIONAL_ENVIRONMENT, LITH_CODE]\n",
            "Index: []\n",
            "model score: 0.854\n",
            "Empty DataFrame\n",
            "Columns: [MD, GR, RT, DEN, CN, DEPOSITIONAL_ENVIRONMENT, LITH_CODE]\n",
            "Index: []\n",
            "model score: 0.854\n",
            "Empty DataFrame\n",
            "Columns: [MD, GR, RT, DEN, CN, DEPOSITIONAL_ENVIRONMENT, LITH_CODE]\n",
            "Index: []\n",
            "model score: 0.855\n",
            "Empty DataFrame\n",
            "Columns: [MD, GR, RT, DEN, CN, DEPOSITIONAL_ENVIRONMENT, LITH_CODE]\n",
            "Index: []\n",
            "model score: 0.853\n",
            "Empty DataFrame\n",
            "Columns: [MD, GR, RT, DEN, CN, DEPOSITIONAL_ENVIRONMENT, LITH_CODE]\n",
            "Index: []\n",
            "model score: 0.860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "ZDLCPCxT8Jo7",
        "outputId": "ac8111f4-ba53-43f2-8868-72ef52fa3623"
      },
      "source": [
        "submission_df = pd.DataFrame({i: combined_predictions[i] for i in range(len(combined_predictions))})\n",
        "submission_df.sample(5)"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16197</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2590</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13856</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18424</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6218</th>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0   1   2   3   4   5   6   7   8   ...  25  26  27  28  29  30  31  32  33\n",
              "16197   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   1   1   1   1   1\n",
              "2590    5   5   5   5   5   5   5   5   5  ...   5   3   5   5   5   5   5   5   3\n",
              "13856   2   2   2   2   2   2   2   2   2  ...   2   2   2   2   0   2   2   2   2\n",
              "18424  10  10  10  10  10  10  10  10  10  ...  10  10  10  10  10  10  10  10  10\n",
              "6218    6  10  10   6   6  10  10  10  10  ...   6  10   6  10   6   6   6   6  10\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrxFPR2--SBt"
      },
      "source": [
        "def most_frequent(List):\n",
        "    occurence_count = collections.Counter(List)\n",
        "    return occurence_count.most_common(1)[0][0]"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH3bgexz9ykv"
      },
      "source": [
        "sub = []\n",
        "for row in range(len(submission_df)):\n",
        "    sub.append(most_frequent(submission_df.loc[row].to_list()))"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GptkcAKW-E2b"
      },
      "source": [
        "predictions = []\n",
        "for pred in sub:\n",
        "    predictions.append(decoder[pred])\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKIT7PQ_BKnm"
      },
      "source": [
        "np.savetxt('prediction_ensemble.csv', predictions, delimiter=',', encoding='utf-8') "
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXI_gJyjDfVw"
      },
      "source": [
        "# After submitting I have checked and found that there is an outlier in column 'RT'\n",
        "# I think it would help to boost the score even higher"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "nQVyTC5HmJNR",
        "outputId": "eee5496e-eb90-4e46-d5b5-01c61f112270"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>MD</th>\n",
              "      <th>GR</th>\n",
              "      <th>RT</th>\n",
              "      <th>CN</th>\n",
              "      <th>DEN</th>\n",
              "      <th>LITH_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "      <td>45749.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.670183</td>\n",
              "      <td>1.428714</td>\n",
              "      <td>1289.498006</td>\n",
              "      <td>84.873762</td>\n",
              "      <td>5.385460</td>\n",
              "      <td>0.345358</td>\n",
              "      <td>2.201688</td>\n",
              "      <td>594.933223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.015506</td>\n",
              "      <td>1.099132</td>\n",
              "      <td>387.339595</td>\n",
              "      <td>15.915062</td>\n",
              "      <td>74.537883</td>\n",
              "      <td>0.076597</td>\n",
              "      <td>0.152785</td>\n",
              "      <td>374.113902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.364000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>640.983000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.444750</td>\n",
              "      <td>0.062000</td>\n",
              "      <td>1.381500</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.756400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>980.300000</td>\n",
              "      <td>75.904300</td>\n",
              "      <td>3.130500</td>\n",
              "      <td>0.292170</td>\n",
              "      <td>2.098700</td>\n",
              "      <td>400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.310900</td>\n",
              "      <td>1.983300</td>\n",
              "      <td>1231.900000</td>\n",
              "      <td>86.297800</td>\n",
              "      <td>3.750600</td>\n",
              "      <td>0.333630</td>\n",
              "      <td>2.197695</td>\n",
              "      <td>500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.091200</td>\n",
              "      <td>1562.183000</td>\n",
              "      <td>95.251900</td>\n",
              "      <td>4.652600</td>\n",
              "      <td>0.387720</td>\n",
              "      <td>2.330100</td>\n",
              "      <td>600.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2275.600000</td>\n",
              "      <td>146.509000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>0.794296</td>\n",
              "      <td>2.725900</td>\n",
              "      <td>1500.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  X             Y  ...           DEN     LITH_CODE\n",
              "count  45749.000000  45749.000000  ...  45749.000000  45749.000000\n",
              "mean       1.670183      1.428714  ...      2.201688    594.933223\n",
              "std        1.015506      1.099132  ...      0.152785    374.113902\n",
              "min        0.364000      0.000000  ...      1.381500    100.000000\n",
              "25%        0.756400      0.000000  ...      2.098700    400.000000\n",
              "50%        1.310900      1.983300  ...      2.197695    500.000000\n",
              "75%        3.000000      2.091200  ...      2.330100    600.000000\n",
              "max        3.000000      3.000000  ...      2.725900   1500.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Krd4mRb-mJ36",
        "outputId": "c5da6988-4a15-4cc3-a7be-4056240d23f9"
      },
      "source": [
        "df[df['RT'] != df['RT'].max()].describe()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>MD</th>\n",
              "      <th>GR</th>\n",
              "      <th>RT</th>\n",
              "      <th>CN</th>\n",
              "      <th>DEN</th>\n",
              "      <th>LITH_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>45740.000000</td>\n",
              "      <td>45740.000000</td>\n",
              "      <td>45740.000000</td>\n",
              "      <td>45740.000000</td>\n",
              "      <td>45740.000000</td>\n",
              "      <td>45740.000000</td>\n",
              "      <td>45740.000000</td>\n",
              "      <td>45740.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.670253</td>\n",
              "      <td>1.428583</td>\n",
              "      <td>1289.624725</td>\n",
              "      <td>84.876400</td>\n",
              "      <td>4.402698</td>\n",
              "      <td>0.345294</td>\n",
              "      <td>2.201757</td>\n",
              "      <td>594.912549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.015593</td>\n",
              "      <td>1.099201</td>\n",
              "      <td>387.272329</td>\n",
              "      <td>15.915355</td>\n",
              "      <td>25.444036</td>\n",
              "      <td>0.076466</td>\n",
              "      <td>0.152706</td>\n",
              "      <td>374.135533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.364000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>640.983000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.444750</td>\n",
              "      <td>0.062000</td>\n",
              "      <td>1.381500</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.756400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>980.495750</td>\n",
              "      <td>75.917375</td>\n",
              "      <td>3.130470</td>\n",
              "      <td>0.292167</td>\n",
              "      <td>2.098768</td>\n",
              "      <td>400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.310900</td>\n",
              "      <td>1.983300</td>\n",
              "      <td>1232.000000</td>\n",
              "      <td>86.300915</td>\n",
              "      <td>3.750365</td>\n",
              "      <td>0.333610</td>\n",
              "      <td>2.197700</td>\n",
              "      <td>500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.091200</td>\n",
              "      <td>1562.220750</td>\n",
              "      <td>95.254150</td>\n",
              "      <td>4.651915</td>\n",
              "      <td>0.387665</td>\n",
              "      <td>2.330200</td>\n",
              "      <td>600.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2275.600000</td>\n",
              "      <td>146.509000</td>\n",
              "      <td>4748.809300</td>\n",
              "      <td>0.794296</td>\n",
              "      <td>2.725900</td>\n",
              "      <td>1500.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  X             Y  ...           DEN     LITH_CODE\n",
              "count  45740.000000  45740.000000  ...  45740.000000  45740.000000\n",
              "mean       1.670253      1.428583  ...      2.201757    594.912549\n",
              "std        1.015593      1.099201  ...      0.152706    374.135533\n",
              "min        0.364000      0.000000  ...      1.381500    100.000000\n",
              "25%        0.756400      0.000000  ...      2.098768    400.000000\n",
              "50%        1.310900      1.983300  ...      2.197700    500.000000\n",
              "75%        3.000000      2.091200  ...      2.330200    600.000000\n",
              "max        3.000000      3.000000  ...      2.725900   1500.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szUyuE0tmhiu",
        "outputId": "b01eb38f-68b8-4f52-e638-08838dd2022f"
      },
      "source": [
        "df['RT'].sort_values(ascending=False)[10:20]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19232    1997.63924\n",
              "19243    1621.56418\n",
              "10250     228.76410\n",
              "10251     225.03630\n",
              "1811      161.58300\n",
              "1812      150.93400\n",
              "10252     142.46629\n",
              "10249     135.86700\n",
              "1810      131.37000\n",
              "10255     116.31100\n",
              "Name: RT, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "MpjTB_ILm2Ul",
        "outputId": "98765c3c-1903-4c7c-8850-0d1b2eb18c77"
      },
      "source": [
        "df[df['RT'] < 1600].describe()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>MD</th>\n",
              "      <th>GR</th>\n",
              "      <th>RT</th>\n",
              "      <th>CN</th>\n",
              "      <th>DEN</th>\n",
              "      <th>LITH_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>45737.000000</td>\n",
              "      <td>45737.000000</td>\n",
              "      <td>45737.000000</td>\n",
              "      <td>45737.000000</td>\n",
              "      <td>45737.000000</td>\n",
              "      <td>45737.000000</td>\n",
              "      <td>45737.000000</td>\n",
              "      <td>45737.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.670277</td>\n",
              "      <td>1.428540</td>\n",
              "      <td>1289.666963</td>\n",
              "      <td>84.877239</td>\n",
              "      <td>4.220028</td>\n",
              "      <td>0.345277</td>\n",
              "      <td>2.201774</td>\n",
              "      <td>594.916588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.015622</td>\n",
              "      <td>1.099224</td>\n",
              "      <td>387.249911</td>\n",
              "      <td>15.915316</td>\n",
              "      <td>3.346688</td>\n",
              "      <td>0.076436</td>\n",
              "      <td>0.152691</td>\n",
              "      <td>374.147276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.364000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>640.983000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.444750</td>\n",
              "      <td>0.062000</td>\n",
              "      <td>1.381500</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.756400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>980.500000</td>\n",
              "      <td>75.917600</td>\n",
              "      <td>3.130410</td>\n",
              "      <td>0.292160</td>\n",
              "      <td>2.098790</td>\n",
              "      <td>400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.310900</td>\n",
              "      <td>1.983300</td>\n",
              "      <td>1232.000000</td>\n",
              "      <td>86.301300</td>\n",
              "      <td>3.750300</td>\n",
              "      <td>0.333610</td>\n",
              "      <td>2.197740</td>\n",
              "      <td>500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.091200</td>\n",
              "      <td>1562.283000</td>\n",
              "      <td>95.255500</td>\n",
              "      <td>4.651800</td>\n",
              "      <td>0.387650</td>\n",
              "      <td>2.330200</td>\n",
              "      <td>600.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2275.600000</td>\n",
              "      <td>146.509000</td>\n",
              "      <td>228.764100</td>\n",
              "      <td>0.794296</td>\n",
              "      <td>2.725900</td>\n",
              "      <td>1500.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  X             Y  ...           DEN     LITH_CODE\n",
              "count  45737.000000  45737.000000  ...  45737.000000  45737.000000\n",
              "mean       1.670277      1.428540  ...      2.201774    594.916588\n",
              "std        1.015622      1.099224  ...      0.152691    374.147276\n",
              "min        0.364000      0.000000  ...      1.381500    100.000000\n",
              "25%        0.756400      0.000000  ...      2.098790    400.000000\n",
              "50%        1.310900      1.983300  ...      2.197740    500.000000\n",
              "75%        3.000000      2.091200  ...      2.330200    600.000000\n",
              "max        3.000000      3.000000  ...      2.725900   1500.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFCLJPmVnY-e"
      },
      "source": [
        "df_outlier = df[df['RT'] < 1600]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "614uY8PEndQ2",
        "outputId": "b873d5eb-aabe-40ea-875f-0e315bc5a95a"
      },
      "source": [
        "collections.Counter(df_outlier['LITH_CODE'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({100: 7716,\n",
              "         200: 3,\n",
              "         300: 1236,\n",
              "         400: 8054,\n",
              "         500: 6491,\n",
              "         600: 11568,\n",
              "         800: 693,\n",
              "         1000: 2544,\n",
              "         1100: 443,\n",
              "         1200: 889,\n",
              "         1300: 5677,\n",
              "         1400: 83,\n",
              "         1500: 340})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isCs2s-0ox4o"
      },
      "source": [
        "X = df_outlier[feature]\n",
        "y = df_outlier['LITH_CODE'].apply(lambda x: encoder[x])\n",
        "X_val = df_val[feature]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBPJ6Dv9pBfm",
        "outputId": "a1a5db86-17e4-4199-e35a-6795427e44dc"
      },
      "source": [
        "collections.Counter(y_train)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 714,\n",
              "         1: 4517,\n",
              "         2: 9227,\n",
              "         3: 358,\n",
              "         4: 64,\n",
              "         5: 6139,\n",
              "         6: 276,\n",
              "         7: 561,\n",
              "         8: 5197,\n",
              "         9: 999,\n",
              "         10: 6488,\n",
              "         11: 2,\n",
              "         12: 2047})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI-3ycM8pEPu",
        "outputId": "e945b491-2cdb-4e03-83f4-0786ee32a5b8"
      },
      "source": [
        "collections.Counter(y_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 175,\n",
              "         1: 1160,\n",
              "         2: 2341,\n",
              "         3: 85,\n",
              "         4: 19,\n",
              "         5: 1577,\n",
              "         6: 64,\n",
              "         7: 132,\n",
              "         8: 1294,\n",
              "         9: 237,\n",
              "         10: 1566,\n",
              "         11: 1,\n",
              "         12: 497})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AYJ7aE9pFwc",
        "outputId": "1d3fafca-0e2d-4120-8938-85c6e2234b2f"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"rbf\"),\n",
        "    xgb.XGBClassifier(),\n",
        "    LGBMClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier()\n",
        "]\n",
        "for classifier in classifiers:\n",
        "    preprocessor = data_preprocessing(X_train,\n",
        "                                      categorical_features,\n",
        "                                      numeric_features,\n",
        "                                      StandardScaler())\n",
        "\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                          ('model', classifier)])\n",
        "    pipe.fit(X_train, y_train)   \n",
        "    print(classifier)\n",
        "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
        "    print(\"F1 score: %.3f\" % f1_score(y_test, pipe.predict(X_test), average='weighted'))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
            "                     weights='uniform')\n",
            "model score: 0.860\n",
            "F1 score: 0.860\n",
            "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "model score: 0.794\n",
            "F1 score: 0.769\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "model score: 0.833\n",
            "F1 score: 0.816\n",
            "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
            "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
            "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
            "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
            "model score: 0.780\n",
            "F1 score: 0.780\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "model score: 0.909\n",
            "F1 score: 0.906\n",
            "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
            "                   n_estimators=50, random_state=None)\n",
            "model score: 0.572\n",
            "F1 score: 0.558\n",
            "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='deprecated',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "model score: 0.860\n",
            "F1 score: 0.850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XEcEjuzrTS4",
        "outputId": "8ab58857-ea13-4007-de44-61b0129eb461"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "classifiers = RandomForestClassifier(max_depth=10,\n",
        "                                     n_estimators=150)\n",
        "preprocessor = data_preprocessing(X_train,\n",
        "                                    categorical_features,\n",
        "                                    numeric_features,\n",
        "                                    StandardScaler())\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "pipe.fit(X_train, y_train)   \n",
        "print(classifier)\n",
        "print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
        "print(\"F1 score: %.3f\" % f1_score(y_test, pipe.predict(X_test), average='weighted'))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='deprecated',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "model score: 0.860\n",
            "F1 score: 0.850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR72rHaypl7l"
      },
      "source": [
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"rbf\"),\n",
        "    xgb.XGBClassifier(),\n",
        "    LGBMClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier()\n",
        "]\n",
        "for classifier in classifiers:\n",
        "    preprocessor = data_preprocessing(X_train,\n",
        "                                      categorical_features,\n",
        "                                      numeric_features,\n",
        "                                      StandardScaler())\n",
        "\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                          ('model', classifier)])\n",
        "    pipe.fit(X_train, y_train)   \n",
        "    print(classifier)\n",
        "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
        "    print(\"F1 score: %.3f\" % f1_score(y_test, pipe.predict(X_test), average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhZNsAKxrRKp",
        "outputId": "0c790594-3b37-4e86-ff79-1fb7243d0e2a"
      },
      "source": [
        "classifier = xgb.XGBClassifier()\n",
        "\n",
        "preprocessor = data_preprocessing(X_train,\n",
        "                                  categorical_features,\n",
        "                                  numeric_features,\n",
        "                                  StandardScaler())\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "\n",
        "param_grid = {\n",
        "    'model__eta': [0.01, 0.1, 0.2, 0.3],\n",
        "    'model__min_child_weight': [1, 2, 3],\n",
        "    #'model__max_depth': np.arange(2, 11, 1),\n",
        "    #'model__subsample': np.arange(0.5, 1.1, 0.1),\n",
        "    #'model__colsample_bytree': np.arange(0.5, 1.1, 0.1)\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(estimator=pipe, cv=5,\n",
        "                  param_grid=param_grid)\n",
        "cv.fit(X_train, y_train)\n",
        "print(classifier)\n",
        "print(cv.best_params_)\n",
        "print(\"model score: %.3f\" % cv.best_estimator_.score(X_test, y_test))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "{'model__eta': 0.01, 'model__min_child_weight': 2}\n",
            "model score: 0.834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jPh31k5aZ9y",
        "outputId": "165de6d0-7049-4459-cb32-5f0d56f2ca41"
      },
      "source": [
        "print(\"F1 score: %.3f\" % f1_score(y_test, cv.best_estimator_.predict(X_test), average='weighted'))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score: 0.817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujui0lEgbA3D",
        "outputId": "12454900-1596-459c-8ba0-209a17f47406"
      },
      "source": [
        "classifier = xgb.XGBClassifier()\n",
        "\n",
        "preprocessor = data_preprocessing(X_train,\n",
        "                                  categorical_features,\n",
        "                                  numeric_features,\n",
        "                                  StandardScaler())\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "\n",
        "param_grid = {\n",
        "    'model__eta': [0.01],\n",
        "    'model__min_child_weight': [2],\n",
        "    'model__max_depth': np.arange(2, 11, 1),\n",
        "    #'model__subsample': np.arange(0.5, 1.1, 0.1),\n",
        "    #'model__colsample_bytree': np.arange(0.5, 1.1, 0.1)\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(estimator=pipe, cv=5,\n",
        "                  param_grid=param_grid)\n",
        "cv.fit(X_train, y_train)\n",
        "print(classifier)\n",
        "print(cv.best_params_)\n",
        "print(\"model score: %.3f\" % cv.best_estimator_.score(X_test, y_test))\n",
        "print(\"F1 score: %.3f\" % f1_score(y_test, cv.best_estimator_.predict(X_test), average='weighted'))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "{'model__eta': 0.01, 'model__max_depth': 10, 'model__min_child_weight': 2}\n",
            "model score: 0.923\n",
            "F1 score: 0.922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7dMX7ODi4yj",
        "outputId": "6c0ca506-2e7b-4696-cf3a-a5bfdf49ef0f"
      },
      "source": [
        "classifier = xgb.XGBClassifier()\n",
        "\n",
        "preprocessor = data_preprocessing(X_train,\n",
        "                                  categorical_features,\n",
        "                                  numeric_features,\n",
        "                                  StandardScaler())\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "\n",
        "param_grid = {\n",
        "    'model__eta': [0.01],\n",
        "    'model__min_child_weight': [2],\n",
        "    'model__max_depth': [10],\n",
        "    'model__subsample': np.arange(0.5, 1.1, 0.1),\n",
        "    #'model__colsample_bytree': np.arange(0.5, 1.1, 0.1)\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(estimator=pipe, cv=5,\n",
        "                  param_grid=param_grid)\n",
        "cv.fit(X_train, y_train)\n",
        "print(classifier)\n",
        "print(cv.best_params_)\n",
        "print(\"model score: %.3f\" % cv.best_estimator_.score(X_test, y_test))\n",
        "print(\"F1 score: %.3f\" % f1_score(y_test, cv.best_estimator_.predict(X_test), average='weighted'))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "{'model__eta': 0.01, 'model__max_depth': 10, 'model__min_child_weight': 2, 'model__subsample': 0.7999999999999999}\n",
            "model score: 0.926\n",
            "F1 score: 0.924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYmNdmU4pRTz",
        "outputId": "ae271f9f-d402-406b-ac03-d88e80595e00"
      },
      "source": [
        "classifier = xgb.XGBClassifier()\n",
        "\n",
        "preprocessor = data_preprocessing(X_train,\n",
        "                                  categorical_features,\n",
        "                                  numeric_features,\n",
        "                                  StandardScaler())\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "\n",
        "param_grid = {\n",
        "    'model__eta': [0.01],\n",
        "    'model__min_child_weight': [2],\n",
        "    'model__max_depth': [10],\n",
        "    'model__subsample': [0.8],\n",
        "    'model__colsample_bytree': 1\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(estimator=pipe, cv=5,\n",
        "                  param_grid=param_grid)\n",
        "cv.fit(X_train, y_train)\n",
        "print(classifier)\n",
        "print(cv.best_params_)\n",
        "print(\"model score: %.3f\" % cv.best_estimator_.score(X_test, y_test))\n",
        "print(\"F1 score: %.3f\" % f1_score(y_test, cv.best_estimator_.predict(X_test), average='weighted'))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "{'model__colsample_bytree': 0.9999999999999999, 'model__eta': 0.01, 'model__max_depth': 10, 'model__min_child_weight': 2, 'model__subsample': 0.8}\n",
            "model score: 0.926\n",
            "F1 score: 0.924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvMNi2iKvwbK",
        "outputId": "e7dadbd1-cf3b-44de-e7fc-07623e0178c8"
      },
      "source": [
        "classifier = xgb.XGBClassifier(\n",
        "    eta=0.01,\n",
        "    min_child_weight=2,\n",
        "    max_depth=10,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=1\n",
        ")\n",
        "\n",
        "preprocessor = data_preprocessing(X_train,\n",
        "                                  categorical_features,\n",
        "                                  numeric_features,\n",
        "                                  StandardScaler())\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "print(classifier)\n",
        "print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
        "print(\"F1 score: %.3f\" % f1_score(y_test, pipe.predict(X_test), average='weighted'))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.926\n",
            "F1 score: 0.924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5gzoweauzuR",
        "outputId": "059d0dd0-7e3a-44d3-dd5d-78112c1f8f63"
      },
      "source": [
        "classifier = xgb.XGBClassifier(\n",
        "    eta=0.01,\n",
        "    min_child_weight=2,\n",
        "    max_depth=10,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=1\n",
        ")\n",
        "\n",
        "preprocessor = data_preprocessing(X_train,\n",
        "                                  categorical_features,\n",
        "                                  numeric_features,\n",
        "                                  StandardScaler())\n",
        "classes_weights = class_weight.compute_sample_weight(\n",
        "    class_weight='balanced',\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "\n",
        "\n",
        "pipe.fit(X_train, y_train, model__sample_weight=classes_weights)\n",
        "print(classifier)\n",
        "print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
        "print(\"F1 score: %.3f\" % f1_score(y_test, pipe.predict(X_test), average='weighted'))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.918\n",
            "F1 score: 0.919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlzwH0Lkspv9",
        "outputId": "015934e8-4ddd-41b2-cd0f-6ff88807c027"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "classifiers = xgb.XGBClassifier()\n",
        "\n",
        "preprocessor = data_preprocessing(X_train,\n",
        "                                    categorical_features,\n",
        "                                    numeric_features,\n",
        "                                    StandardScaler())\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('model', classifier)])\n",
        "\n",
        "classes_weights = class_weight.compute_sample_weight(\n",
        "    class_weight='balanced',\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "pipe.fit(X_train, y_train, model__sample_weight=classes_weights)   \n",
        "print(classifier)\n",
        "print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
        "print(\"F1 score: %.3f\" % f1_score(y_test, pipe.predict(X_test), average='weighted'))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='deprecated',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "model score: 0.821\n",
            "F1 score: 0.828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYChu6AmuLjl",
        "outputId": "bd55357a-be38-4b3a-fcce-0956ccdc9bea"
      },
      "source": [
        "max_samples = 1000\n",
        "for j in range(10):\n",
        "    new_df = pd.DataFrame(columns = df_train.columns.to_list())\n",
        "    for key in df_train['LITH_CODE'].unique():\n",
        "        if len(df_train[df_train['LITH_CODE'] == key]) < max_samples:\n",
        "            new_df = new_df.append(df_train[df_train['LITH_CODE'] == key])\n",
        "        else:\n",
        "            temp = df_train[df_train['LITH_CODE'] == key].sample(max_samples, random_state=np.random.randint(1, 200))\n",
        "            new_df = new_df.append(temp)\n",
        "    y_new_df = new_df['LITH_CODE']\n",
        "    X_new_df = new_df.drop(columns=['LITH_CODE'])\n",
        "    classifier = xgb.XGBClassifier(\n",
        "        eta=0.01,\n",
        "        min_child_weight=2,\n",
        "        max_depth=10,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=1\n",
        "    )\n",
        "\n",
        "    preprocessor = data_preprocessing(X_new_df,\n",
        "                                    categorical_features,\n",
        "                                    numeric_features,\n",
        "                                    StandardScaler())\n",
        "\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                            ('model', classifier)])\n",
        "\n",
        "\n",
        "    pipe.fit(X_new_df, y_new_df.astype('int'))\n",
        "    print(classifier)\n",
        "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
        "    print(\"F1 score: %.3f\" % f1_score(y_test, pipe.predict(X_test), average='weighted'))\n",
        "    #combined_predictions.append(pipe.predict(X_val))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.870\n",
            "F1 score: 0.876\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.865\n",
            "F1 score: 0.871\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.872\n",
            "F1 score: 0.876\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.867\n",
            "F1 score: 0.872\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.872\n",
            "F1 score: 0.876\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.867\n",
            "F1 score: 0.872\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.871\n",
            "F1 score: 0.875\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.872\n",
            "F1 score: 0.877\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.870\n",
            "F1 score: 0.875\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.868\n",
            "F1 score: 0.873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvoL5RhU65fc",
        "outputId": "3598df01-7db6-40b3-8f96-94370718b9f4"
      },
      "source": [
        "max_samples = 3000\n",
        "for j in range(10):\n",
        "    new_df = pd.DataFrame(columns = df_train.columns.to_list())\n",
        "    for key in df_train['LITH_CODE'].unique():\n",
        "        if len(df_train[df_train['LITH_CODE'] == key]) < max_samples:\n",
        "            new_df = new_df.append(df_train[df_train['LITH_CODE'] == key])\n",
        "        else:\n",
        "            temp = df_train[df_train['LITH_CODE'] == key].sample(max_samples, random_state=np.random.randint(1, 200))\n",
        "            new_df = new_df.append(temp)\n",
        "    y_new_df = new_df['LITH_CODE']\n",
        "    X_new_df = new_df.drop(columns=['LITH_CODE'])\n",
        "    classifier = xgb.XGBClassifier(\n",
        "        eta=0.01,\n",
        "        min_child_weight=2,\n",
        "        max_depth=10,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=1,\n",
        "        objective='auc'\n",
        "    )\n",
        "\n",
        "    preprocessor = data_preprocessing(X_new_df,\n",
        "                                    categorical_features,\n",
        "                                    numeric_features,\n",
        "                                    StandardScaler())\n",
        "\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                            ('model', classifier)])\n",
        "\n",
        "\n",
        "    pipe.fit(X_new_df, y_new_df.astype('int'))\n",
        "    print(classifier)\n",
        "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
        "    print(\"F1 score: %.3f\" % f1_score(y_test, pipe.predict(X_test), average='weighted'))\n",
        "    #combined_predictions.append(pipe.predict(X_val))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.915\n",
            "F1 score: 0.915\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.918\n",
            "F1 score: 0.919\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.916\n",
            "F1 score: 0.916\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.913\n",
            "F1 score: 0.914\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.915\n",
            "F1 score: 0.915\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.914\n",
            "F1 score: 0.915\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.915\n",
            "F1 score: 0.915\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.916\n",
            "F1 score: 0.916\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.914\n",
            "F1 score: 0.915\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.913\n",
            "F1 score: 0.913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE2Df64h71jI",
        "outputId": "6245726f-1e5d-41b4-99b2-dfeb63cf46e0"
      },
      "source": [
        "f1_score(y_new_df.astype('int'), pipe.predict(X_new_df), average='weighted')"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9909067095828835"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsLgf67H9gJS"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gUh5PfI92UM",
        "outputId": "d6034fe7-928a-4d26-e342-ac4e6f010e33"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=10, random_state=7)\n",
        "cross_val_score(pipe, X_new_df, y_new_df.astype('int'), cv=kfold)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.89476309, 0.89177057, 0.9032419 , 0.89526185, 0.8872818 ,\n",
              "       0.88678304, 0.8882793 , 0.89226933, 0.89326683, 0.90374065])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eowm8P9c9_tD",
        "outputId": "a261ef9f-4557-4de0-cbf6-423813fc4bfd"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=10, random_state=7)\n",
        "cross_val_score(pipe, df[feature], df['LITH_CODE'], cv=kfold)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.68437158, 0.75387978, 0.75912568, 0.69355191, 0.69879781,\n",
              "       0.73704918, 0.68284153, 0.85464481, 0.85464481, 0.51268037])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCxI_9oz_eEn",
        "outputId": "08b66c7e-b7ef-4f33-c7b3-ac49efafcf40"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=10, random_state=7)\n",
        "cross_val_score(pipe, df_outlier[feature], df_outlier['LITH_CODE'], cv=kfold)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.68320944, 0.75120245, 0.76038478, 0.69348491, 0.70332313,\n",
              "       0.73874071, 0.68495846, 0.85458124, 0.85392521, 0.53269189])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY8NvbCuCyfg",
        "outputId": "08544e14-0217-4b60-d66e-b9ef7fc2bdf4"
      },
      "source": [
        "max_samples = 3500\n",
        "for j in range(10):\n",
        "    new_df = pd.DataFrame(columns = df_train.columns.to_list())\n",
        "    for key in df_train['LITH_CODE'].unique():\n",
        "        if len(df_train[df_train['LITH_CODE'] == key]) < max_samples:\n",
        "            new_df = new_df.append(df_train[df_train['LITH_CODE'] == key])\n",
        "        else:\n",
        "            temp = df_train[df_train['LITH_CODE'] == key].sample(max_samples, random_state=np.random.randint(1, 200))\n",
        "            new_df = new_df.append(temp)\n",
        "    y_new_df = new_df['LITH_CODE']\n",
        "    X_new_df = new_df.drop(columns=['LITH_CODE'])\n",
        "    classifier = xgb.XGBClassifier(\n",
        "        eta=0.01,\n",
        "        min_child_weight=2,\n",
        "        max_depth=10,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=1,\n",
        "        objective='auc'\n",
        "    )\n",
        "\n",
        "    preprocessor = data_preprocessing(X_new_df,\n",
        "                                    categorical_features,\n",
        "                                    numeric_features,\n",
        "                                    StandardScaler())\n",
        "\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                            ('model', classifier)])\n",
        "\n",
        "\n",
        "    pipe.fit(X_new_df, y_new_df.astype('int'))\n",
        "    print(classifier)\n",
        "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
        "    print(\"F1 score: %.3f\" % f1_score(y_test, pipe.predict(X_test), average='weighted'))\n",
        "    #combined_predictions.append(pipe.predict(X_val))"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.920\n",
            "F1 score: 0.920\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.917\n",
            "F1 score: 0.917\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.919\n",
            "F1 score: 0.919\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.916\n",
            "F1 score: 0.916\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.918\n",
            "F1 score: 0.918\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.919\n",
            "F1 score: 0.919\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.917\n",
            "F1 score: 0.917\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.919\n",
            "F1 score: 0.919\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.918\n",
            "F1 score: 0.918\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
            "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "model score: 0.919\n",
            "F1 score: 0.918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-zLJ_fKJH_W",
        "outputId": "326a30d0-8df6-4b65-f718-7aa85d4157e0"
      },
      "source": [
        "combined_predictions = {}\n",
        "max_samples = 3500\n",
        "acc = {}\n",
        "for j in range(10):\n",
        "    new_df = pd.DataFrame(columns = df_train.columns.to_list())\n",
        "    for key in df_train['LITH_CODE'].unique():\n",
        "        if len(df_train[df_train['LITH_CODE'] == key]) < max_samples:\n",
        "            new_df = new_df.append(df_train[df_train['LITH_CODE'] == key])\n",
        "        else:\n",
        "            temp = df_train[df_train['LITH_CODE'] == key].sample(max_samples, random_state=np.random.randint(1, 200))\n",
        "            new_df = new_df.append(temp)\n",
        "    y_new_df = new_df['LITH_CODE']\n",
        "    X_new_df = new_df.drop(columns=['LITH_CODE'])\n",
        "    classifier = xgb.XGBClassifier(\n",
        "        eta=0.01,\n",
        "        min_child_weight=2,\n",
        "        max_depth=10,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=1,\n",
        "        objective='auc'\n",
        "    )\n",
        "\n",
        "    preprocessor = data_preprocessing(X_new_df,\n",
        "                                    categorical_features,\n",
        "                                    numeric_features,\n",
        "                                    StandardScaler())\n",
        "\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                            ('model', classifier)])\n",
        "\n",
        "\n",
        "    pipe.fit(X_new_df, y_new_df.astype('int'))\n",
        "    #print(classifier)\n",
        "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
        "    f1 = f1_score(y_test, pipe.predict(X_test), average='weighted')\n",
        "    print(\"F1 score: %.3f\" % f1)\n",
        "    acc[j] = f1\n",
        "    combined_predictions[j] = pipe.predict(X_val)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model score: 0.920\n",
            "F1 score: 0.920\n",
            "model score: 0.921\n",
            "F1 score: 0.921\n",
            "model score: 0.917\n",
            "F1 score: 0.917\n",
            "model score: 0.916\n",
            "F1 score: 0.917\n",
            "model score: 0.920\n",
            "F1 score: 0.920\n",
            "model score: 0.916\n",
            "F1 score: 0.916\n",
            "model score: 0.915\n",
            "F1 score: 0.915\n",
            "model score: 0.917\n",
            "F1 score: 0.917\n",
            "model score: 0.920\n",
            "F1 score: 0.920\n",
            "model score: 0.918\n",
            "F1 score: 0.918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcdEcfA6QkD8",
        "outputId": "63586272-5ddf-404c-b88b-15a74346d0af"
      },
      "source": [
        "acc"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.9198034131319924,\n",
              " 1: 0.9205901715831966,\n",
              " 2: 0.917066191116951,\n",
              " 3: 0.9165276236568299,\n",
              " 4: 0.9195801455247599,\n",
              " 5: 0.9159129614037008,\n",
              " 6: 0.9152640521922015,\n",
              " 7: 0.9171524200870815,\n",
              " 8: 0.9197868193311758,\n",
              " 9: 0.9176313977853888}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "aw-fL6HOPfPS",
        "outputId": "dc0e30df-7868-4577-cbd6-47ae43ef16d4"
      },
      "source": [
        "array = [0, 1, 4, 8, 9]\n",
        "submission_df = pd.DataFrame({idx: combined_predictions[i] for idx, i in enumerate(array)})\n",
        "submission_df.sample(5)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20470</th>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10335</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15668</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18941</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14988</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0   1   2   3   4\n",
              "20470  12  12  12  12  12\n",
              "10335   8   8   8   8   8\n",
              "15668   2   2   2   2   2\n",
              "18941   3   3   3   5   3\n",
              "14988   2   2   2   2   2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpIHjGzoRnho"
      },
      "source": [
        "sub = []\n",
        "for row in range(len(submission_df)):\n",
        "    sub.append(most_frequent(submission_df.loc[row].to_list()))\n",
        "predictions = []\n",
        "for pred in sub:\n",
        "    predictions.append(decoder[pred])\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbBs_0JONRSB"
      },
      "source": [
        "predictions = []\n",
        "for pred in sub:\n",
        "    predictions.append(decoder[pred])\n",
        "predictions\n",
        "np.savetxt('prediction_xgb.csv', predictions, delimiter=',', encoding='utf-8') "
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9HdkLPJRVgh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}